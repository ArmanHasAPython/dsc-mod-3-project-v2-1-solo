{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syriatel is the leading mobile telecommunications company based in Damascus, Syria. Their vision is that, by focusing solely on customer satisfaction and social responsibility they are able to present products and services of a high standard. \n",
    "\n",
    "The goal is to continue to drive the excellent standards of the company by predicting whether a customer will churn from doing business with SyriaTel. \n",
    "\n",
    "This will be helped by figuring out identifying the customer likely to churn and negotiate better conditions for them to stay on with the network provider through conversational means.\n",
    "\n",
    "Targeting ALL customers, likely and not-likely to churn will be costly in revenue to the company and therefore it is more economically beneficial to apply the retention measures to those likely to churn only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Questions\n",
    "\n",
    "- Are the lack of international plans provided the reason why customers churn?\n",
    "- Would greater provision at better rates be more likely to keep customers onboard?\n",
    "- Would providing better customer service be more likely to keep customers onboard?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#For Train Test Split\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#DecisionTrees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...    total eve calls  total eve charge  \\\n",
       "0             45.07  ...                 99             16.78   \n",
       "1             27.47  ...                103             16.62   \n",
       "2             41.38  ...                110             10.30   \n",
       "3             50.90  ...                 88              5.26   \n",
       "4             28.34  ...                122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out first 5 rows of the data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "account length\n",
      "area code\n",
      "phone number\n",
      "international plan\n",
      "voice mail plan\n",
      "number vmail messages\n",
      "total day minutes\n",
      "total day calls\n",
      "total day charge\n",
      "total eve minutes\n",
      "total eve calls\n",
      "total eve charge\n",
      "total night minutes\n",
      "total night calls\n",
      "total night charge\n",
      "total intl minutes\n",
      "total intl calls\n",
      "total intl charge\n",
      "customer service calls\n",
      "churn\n"
     ]
    }
   ],
   "source": [
    "#Identifying the columns which will be useful to find which ones to drop later\n",
    "\n",
    "for col in df.columns:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 21)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify the total number of rows and columns\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      "state                     3333 non-null object\n",
      "account length            3333 non-null int64\n",
      "area code                 3333 non-null int64\n",
      "phone number              3333 non-null object\n",
      "international plan        3333 non-null object\n",
      "voice mail plan           3333 non-null object\n",
      "number vmail messages     3333 non-null int64\n",
      "total day minutes         3333 non-null float64\n",
      "total day calls           3333 non-null int64\n",
      "total day charge          3333 non-null float64\n",
      "total eve minutes         3333 non-null float64\n",
      "total eve calls           3333 non-null int64\n",
      "total eve charge          3333 non-null float64\n",
      "total night minutes       3333 non-null float64\n",
      "total night calls         3333 non-null int64\n",
      "total night charge        3333 non-null float64\n",
      "total intl minutes        3333 non-null float64\n",
      "total intl calls          3333 non-null int64\n",
      "total intl charge         3333 non-null float64\n",
      "customer service calls    3333 non-null int64\n",
      "churn                     3333 non-null bool\n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Find the types of data in the set\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our output variable, churn, is a boolean. We will have to change this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                     0\n",
       "account length            0\n",
       "area code                 0\n",
       "phone number              0\n",
       "international plan        0\n",
       "voice mail plan           0\n",
       "number vmail messages     0\n",
       "total day minutes         0\n",
       "total day calls           0\n",
       "total day charge          0\n",
       "total eve minutes         0\n",
       "total eve calls           0\n",
       "total eve charge          0\n",
       "total night minutes       0\n",
       "total night calls         0\n",
       "total night charge        0\n",
       "total intl minutes        0\n",
       "total intl calls          0\n",
       "total intl charge         0\n",
       "customer service calls    0\n",
       "churn                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Investigate the dataset for missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are no missing values in our dataset. This is quite fortunate in this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      object\n",
       "account length              int64\n",
       "area code                   int64\n",
       "phone number               object\n",
       "international plan         object\n",
       "voice mail plan            object\n",
       "number vmail messages       int64\n",
       "total day minutes         float64\n",
       "total day calls             int64\n",
       "total day charge          float64\n",
       "total eve minutes         float64\n",
       "total eve calls             int64\n",
       "total eve charge          float64\n",
       "total night minutes       float64\n",
       "total night calls           int64\n",
       "total night charge        float64\n",
       "total intl minutes        float64\n",
       "total intl calls            int64\n",
       "total intl charge         float64\n",
       "customer service calls      int64\n",
       "churn                        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#State and area code will not be useful variables in our analysis\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The state and customer number columns are unecessary so we will remove those ones\n",
    "\n",
    "df.drop(columns=['state', 'phone number'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2850\n",
      "True      483\n",
      "Name: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Produce a pie chart visualisation to establish the percentage of churners in the dataset\n",
    "\n",
    "sizes = df['churn'].value_counts(sort=True)\n",
    "\n",
    "colors = [\"red\", \"blue\"]\n",
    "labels = 'False', 'True'\n",
    "explode = (0,0.1)\n",
    "plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', colors=colors, shadow=True, startangle=90)\n",
    "plt.title('Percentage of Churn in Customer Data')\n",
    "plt.show()\n",
    "\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen the percentage of true churns in the dataset it would now be helpful to produce a heatmap and identify the useful variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account length              int64\n",
      "area code                   int64\n",
      "international plan          int64\n",
      "voice mail plan             int64\n",
      "number vmail messages       int64\n",
      "total day minutes         float64\n",
      "total day calls             int64\n",
      "total day charge          float64\n",
      "total eve minutes         float64\n",
      "total eve calls             int64\n",
      "total eve charge          float64\n",
      "total night minutes       float64\n",
      "total night calls           int64\n",
      "total night charge        float64\n",
      "total intl minutes        float64\n",
      "total intl calls            int64\n",
      "total intl charge         float64\n",
      "customer service calls      int64\n",
      "churn                        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorical data into numerical data\n",
    "#International plan and voice mail plan\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df['international plan'] = label_encoder.fit_transform(df['international plan'])\n",
    "df['voice mail plan'] = label_encoder.fit_transform(df['voice mail plan'])\n",
    "\n",
    "\n",
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the international plan and voicemail plan have been converted into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the bools of churn into integers\n",
    "\n",
    "df['churn'] = df['churn'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "account length              int64\n",
       "area code                   int64\n",
       "international plan          int64\n",
       "voice mail plan             int64\n",
       "number vmail messages       int64\n",
       "total day minutes         float64\n",
       "total day calls             int64\n",
       "total day charge          float64\n",
       "total eve minutes         float64\n",
       "total eve calls             int64\n",
       "total eve charge          float64\n",
       "total night minutes       float64\n",
       "total night calls           int64\n",
       "total night charge        float64\n",
       "total intl minutes        float64\n",
       "total intl calls            int64\n",
       "total intl charge         float64\n",
       "customer service calls      int64\n",
       "churn                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if the dtype of int has been converted\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have a functioning set of data which will be handy to produce our baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will declare my variables. My target variable (churn) and my predictors are (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account length  international plan  voice mail plan  number vmail messages  \\\n",
       "0             128                   0                1                     25   \n",
       "1             107                   0                1                     26   \n",
       "2             137                   0                0                      0   \n",
       "3              84                   1                0                      0   \n",
       "4              75                   1                0                      0   \n",
       "\n",
       "   total day minutes  total day calls  total day charge  total eve minutes  \\\n",
       "0              265.1              110             45.07              197.4   \n",
       "1              161.6              123             27.47              195.5   \n",
       "2              243.4              114             41.38              121.2   \n",
       "3              299.4               71             50.90               61.9   \n",
       "4              166.7              113             28.34              148.3   \n",
       "\n",
       "   total eve calls  total eve charge  total night minutes  total night calls  \\\n",
       "0               99             16.78                244.7                 91   \n",
       "1              103             16.62                254.4                103   \n",
       "2              110             10.30                162.6                104   \n",
       "3               88              5.26                196.9                 89   \n",
       "4              122             12.61                186.9                121   \n",
       "\n",
       "   total night charge  total intl minutes  total intl calls  \\\n",
       "0               11.01                10.0                 3   \n",
       "1               11.45                13.7                 3   \n",
       "2                7.32                12.2                 5   \n",
       "3                8.86                 6.6                 7   \n",
       "4                8.41                10.1                 3   \n",
       "\n",
       "   total intl charge  customer service calls  \n",
       "0               2.70                       1  \n",
       "1               3.70                       1  \n",
       "2               3.29                       0  \n",
       "3               1.78                       2  \n",
       "4               2.73                       3  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['churn','area code'], axis=1)\n",
    "y = df['churn']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and validation datasets\n",
    "\n",
    "X_train_v, X_val, y_train_v, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the 3 datasets \n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_v) #Fit scaler only on training data\n",
    "\n",
    "X_train_v = ss.transform(X_train_v)\n",
    "X_val = ss.transform(X_val)\n",
    "\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(fit_intercept=True, C=1e12, solver='liblinear', random_state=42)\n",
    "model_log = logreg.fit(X_train_v, y_train_v)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model_log.predict_proba(X_train_v)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8578799249530957"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log.score(X_train_v,y_train_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8801498127340824"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the score for the validation dataset\n",
    "\n",
    "model_log.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the accuracy and ROC_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.8212366413250989\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC_AUC of model =\", roc_auc_score(y_train_v, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.6576992627625539\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model_log.predict(X_val)\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(criterion='gini',max_depth=2, min_samples_leaf=10, \n",
    "                               random_state=100, class_weight=\"balanced\")\n",
    "\n",
    "model_dt.fit(X_train_v, y_train_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.7944190802301803\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_dt.predict_proba(X_train_v)[:,1]\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_train_v, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.73645847823063\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model_dt.predict(X_val)\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=110, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=48,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': range(1, 10),\n",
       "                         'min_samples_leaf': [5, 10, 15, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=110, shuffle=True)\n",
    "ParamGrid = {'max_depth': range(1,10), 'min_samples_leaf': [5,10,15,20]}\n",
    "optimalmodel_dt = GridSearchCV(DecisionTreeClassifier(random_state=48), ParamGrid, cv=skf, scoring=\"roc_auc\")\n",
    "optimalmodel_dt.fit(X_train, y_train) #Here we will use the entire train data set as we are doing cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the optimised hyperparameters\n",
      " for the best model found:\n",
      " {'max_depth': 6, 'min_samples_leaf': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9015292140538281"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Values of the optimised hyperparameters\\n for the best model found:\\n',optimalmodel_dt.best_params_)\n",
    "optimalmodel_dt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.632508</td>\n",
       "      <td>0.622561</td>\n",
       "      <td>0.634204</td>\n",
       "      <td>0.629758</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009218</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.632508</td>\n",
       "      <td>0.622561</td>\n",
       "      <td>0.634204</td>\n",
       "      <td>0.629758</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.632508</td>\n",
       "      <td>0.622561</td>\n",
       "      <td>0.634204</td>\n",
       "      <td>0.629758</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.632508</td>\n",
       "      <td>0.622561</td>\n",
       "      <td>0.634204</td>\n",
       "      <td>0.629758</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.744621</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.747376</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.744621</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.747376</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.744621</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.747376</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.744621</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.747376</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.822989</td>\n",
       "      <td>0.828484</td>\n",
       "      <td>0.834417</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.846478</td>\n",
       "      <td>0.816534</td>\n",
       "      <td>0.835768</td>\n",
       "      <td>0.832927</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.846478</td>\n",
       "      <td>0.820297</td>\n",
       "      <td>0.840332</td>\n",
       "      <td>0.835702</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.017513</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.820989</td>\n",
       "      <td>0.840332</td>\n",
       "      <td>0.837700</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009638</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.905153</td>\n",
       "      <td>0.841065</td>\n",
       "      <td>0.889386</td>\n",
       "      <td>0.878534</td>\n",
       "      <td>0.027266</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.898399</td>\n",
       "      <td>0.838535</td>\n",
       "      <td>0.890965</td>\n",
       "      <td>0.875966</td>\n",
       "      <td>0.026641</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.844631</td>\n",
       "      <td>0.894781</td>\n",
       "      <td>0.880693</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.901665</td>\n",
       "      <td>0.845913</td>\n",
       "      <td>0.897762</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012936</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.925115</td>\n",
       "      <td>0.821107</td>\n",
       "      <td>0.908927</td>\n",
       "      <td>0.885050</td>\n",
       "      <td>0.045695</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.910099</td>\n",
       "      <td>0.856425</td>\n",
       "      <td>0.905091</td>\n",
       "      <td>0.890538</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.921210</td>\n",
       "      <td>0.859898</td>\n",
       "      <td>0.912208</td>\n",
       "      <td>0.897772</td>\n",
       "      <td>0.027032</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.014853</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.916274</td>\n",
       "      <td>0.872188</td>\n",
       "      <td>0.909188</td>\n",
       "      <td>0.899216</td>\n",
       "      <td>0.019330</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.916711</td>\n",
       "      <td>0.837135</td>\n",
       "      <td>0.926516</td>\n",
       "      <td>0.893454</td>\n",
       "      <td>0.040024</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013556</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.914854</td>\n",
       "      <td>0.864761</td>\n",
       "      <td>0.913216</td>\n",
       "      <td>0.897610</td>\n",
       "      <td>0.023238</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.921819</td>\n",
       "      <td>0.865694</td>\n",
       "      <td>0.913718</td>\n",
       "      <td>0.900410</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.923676</td>\n",
       "      <td>0.877385</td>\n",
       "      <td>0.903527</td>\n",
       "      <td>0.901529</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.021532</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.864422</td>\n",
       "      <td>0.851071</td>\n",
       "      <td>0.917535</td>\n",
       "      <td>0.877676</td>\n",
       "      <td>0.028707</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.019094</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.905010</td>\n",
       "      <td>0.860644</td>\n",
       "      <td>0.910811</td>\n",
       "      <td>0.892155</td>\n",
       "      <td>0.022407</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.019299</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.913484</td>\n",
       "      <td>0.863744</td>\n",
       "      <td>0.919797</td>\n",
       "      <td>0.899008</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.911912</td>\n",
       "      <td>0.855035</td>\n",
       "      <td>0.904260</td>\n",
       "      <td>0.890402</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.870341</td>\n",
       "      <td>0.853591</td>\n",
       "      <td>0.902425</td>\n",
       "      <td>0.875452</td>\n",
       "      <td>0.020261</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.887808</td>\n",
       "      <td>0.882886</td>\n",
       "      <td>0.896459</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.013609</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.910251</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>0.893212</td>\n",
       "      <td>0.895997</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.905708</td>\n",
       "      <td>0.881904</td>\n",
       "      <td>0.881024</td>\n",
       "      <td>0.889545</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.017070</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.871446</td>\n",
       "      <td>0.865227</td>\n",
       "      <td>0.906030</td>\n",
       "      <td>0.880901</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.015550</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.898359</td>\n",
       "      <td>0.881408</td>\n",
       "      <td>0.896867</td>\n",
       "      <td>0.892211</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.906985</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>0.888948</td>\n",
       "      <td>0.892236</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.909303</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.886749</td>\n",
       "      <td>0.895354</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.006570      0.000874         0.003299        0.000124   \n",
       "1        0.009218      0.003152         0.003910        0.000766   \n",
       "2        0.010668      0.004723         0.005719        0.001328   \n",
       "3        0.007235      0.002756         0.006340        0.002585   \n",
       "4        0.006063      0.000396         0.002324        0.000088   \n",
       "5        0.012001      0.002155         0.009156        0.002050   \n",
       "6        0.017244      0.008097         0.004576        0.001947   \n",
       "7        0.008316      0.002325         0.002832        0.000384   \n",
       "8        0.009146      0.001957         0.002933        0.000626   \n",
       "9        0.007950      0.000114         0.003311        0.000517   \n",
       "10       0.009051      0.000272         0.003168        0.000487   \n",
       "11       0.017513      0.007228         0.006371        0.005498   \n",
       "12       0.009638      0.000811         0.002918        0.000455   \n",
       "13       0.010769      0.001350         0.004502        0.001431   \n",
       "14       0.009000      0.000373         0.002857        0.000336   \n",
       "15       0.010691      0.001672         0.002812        0.000323   \n",
       "16       0.012936      0.002501         0.006601        0.004930   \n",
       "17       0.013596      0.001436         0.007130        0.003131   \n",
       "18       0.014355      0.001281         0.005078        0.002410   \n",
       "19       0.014853      0.004884         0.002812        0.000230   \n",
       "20       0.012016      0.000869         0.002580        0.000302   \n",
       "21       0.013556      0.002635         0.002888        0.000380   \n",
       "22       0.014095      0.001507         0.008003        0.007805   \n",
       "23       0.011255      0.000405         0.003879        0.000893   \n",
       "24       0.021532      0.005582         0.004263        0.000773   \n",
       "25       0.019094      0.002482         0.004983        0.001733   \n",
       "26       0.019299      0.004526         0.002774        0.000271   \n",
       "27       0.014390      0.001131         0.003075        0.000382   \n",
       "28       0.015183      0.000951         0.005364        0.002158   \n",
       "29       0.016113      0.001850         0.002554        0.000278   \n",
       "30       0.013609      0.000610         0.002922        0.000434   \n",
       "31       0.015509      0.002592         0.003487        0.001049   \n",
       "32       0.017070      0.001630         0.002438        0.000093   \n",
       "33       0.015550      0.002227         0.002827        0.000247   \n",
       "34       0.014971      0.000474         0.002602        0.000194   \n",
       "35       0.015406      0.000278         0.003066        0.000526   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                1                      5   \n",
       "1                1                     10   \n",
       "2                1                     15   \n",
       "3                1                     20   \n",
       "4                2                      5   \n",
       "5                2                     10   \n",
       "6                2                     15   \n",
       "7                2                     20   \n",
       "8                3                      5   \n",
       "9                3                     10   \n",
       "10               3                     15   \n",
       "11               3                     20   \n",
       "12               4                      5   \n",
       "13               4                     10   \n",
       "14               4                     15   \n",
       "15               4                     20   \n",
       "16               5                      5   \n",
       "17               5                     10   \n",
       "18               5                     15   \n",
       "19               5                     20   \n",
       "20               6                      5   \n",
       "21               6                     10   \n",
       "22               6                     15   \n",
       "23               6                     20   \n",
       "24               7                      5   \n",
       "25               7                     10   \n",
       "26               7                     15   \n",
       "27               7                     20   \n",
       "28               8                      5   \n",
       "29               8                     10   \n",
       "30               8                     15   \n",
       "31               8                     20   \n",
       "32               9                      5   \n",
       "33               9                     10   \n",
       "34               9                     15   \n",
       "35               9                     20   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0    {'max_depth': 1, 'min_samples_leaf': 5}           0.632508   \n",
       "1   {'max_depth': 1, 'min_samples_leaf': 10}           0.632508   \n",
       "2   {'max_depth': 1, 'min_samples_leaf': 15}           0.632508   \n",
       "3   {'max_depth': 1, 'min_samples_leaf': 20}           0.632508   \n",
       "4    {'max_depth': 2, 'min_samples_leaf': 5}           0.756184   \n",
       "5   {'max_depth': 2, 'min_samples_leaf': 10}           0.756184   \n",
       "6   {'max_depth': 2, 'min_samples_leaf': 15}           0.756184   \n",
       "7   {'max_depth': 2, 'min_samples_leaf': 20}           0.756184   \n",
       "8    {'max_depth': 3, 'min_samples_leaf': 5}           0.851778   \n",
       "9   {'max_depth': 3, 'min_samples_leaf': 10}           0.846478   \n",
       "10  {'max_depth': 3, 'min_samples_leaf': 15}           0.846478   \n",
       "11  {'max_depth': 3, 'min_samples_leaf': 20}           0.851778   \n",
       "12   {'max_depth': 4, 'min_samples_leaf': 5}           0.905153   \n",
       "13  {'max_depth': 4, 'min_samples_leaf': 10}           0.898399   \n",
       "14  {'max_depth': 4, 'min_samples_leaf': 15}           0.902667   \n",
       "15  {'max_depth': 4, 'min_samples_leaf': 20}           0.901665   \n",
       "16   {'max_depth': 5, 'min_samples_leaf': 5}           0.925115   \n",
       "17  {'max_depth': 5, 'min_samples_leaf': 10}           0.910099   \n",
       "18  {'max_depth': 5, 'min_samples_leaf': 15}           0.921210   \n",
       "19  {'max_depth': 5, 'min_samples_leaf': 20}           0.916274   \n",
       "20   {'max_depth': 6, 'min_samples_leaf': 5}           0.916711   \n",
       "21  {'max_depth': 6, 'min_samples_leaf': 10}           0.914854   \n",
       "22  {'max_depth': 6, 'min_samples_leaf': 15}           0.921819   \n",
       "23  {'max_depth': 6, 'min_samples_leaf': 20}           0.923676   \n",
       "24   {'max_depth': 7, 'min_samples_leaf': 5}           0.864422   \n",
       "25  {'max_depth': 7, 'min_samples_leaf': 10}           0.905010   \n",
       "26  {'max_depth': 7, 'min_samples_leaf': 15}           0.913484   \n",
       "27  {'max_depth': 7, 'min_samples_leaf': 20}           0.911912   \n",
       "28   {'max_depth': 8, 'min_samples_leaf': 5}           0.870341   \n",
       "29  {'max_depth': 8, 'min_samples_leaf': 10}           0.887808   \n",
       "30  {'max_depth': 8, 'min_samples_leaf': 15}           0.910251   \n",
       "31  {'max_depth': 8, 'min_samples_leaf': 20}           0.905708   \n",
       "32   {'max_depth': 9, 'min_samples_leaf': 5}           0.871446   \n",
       "33  {'max_depth': 9, 'min_samples_leaf': 10}           0.898359   \n",
       "34  {'max_depth': 9, 'min_samples_leaf': 15}           0.906985   \n",
       "35  {'max_depth': 9, 'min_samples_leaf': 20}           0.909303   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.622561           0.634204         0.629758        0.005136   \n",
       "1            0.622561           0.634204         0.629758        0.005136   \n",
       "2            0.622561           0.634204         0.629758        0.005136   \n",
       "3            0.622561           0.634204         0.629758        0.005136   \n",
       "4            0.744621           0.741321         0.747376        0.006373   \n",
       "5            0.744621           0.741321         0.747376        0.006373   \n",
       "6            0.744621           0.741321         0.747376        0.006373   \n",
       "7            0.744621           0.741321         0.747376        0.006373   \n",
       "8            0.822989           0.828484         0.834417        0.012480   \n",
       "9            0.816534           0.835768         0.832927        0.012389   \n",
       "10           0.820297           0.840332         0.835702        0.011179   \n",
       "11           0.820989           0.840332         0.837700        0.012707   \n",
       "12           0.841065           0.889386         0.878534        0.027266   \n",
       "13           0.838535           0.890965         0.875966        0.026641   \n",
       "14           0.844631           0.894781         0.880693        0.025702   \n",
       "15           0.845913           0.897762         0.881780        0.025412   \n",
       "16           0.821107           0.908927         0.885050        0.045695   \n",
       "17           0.856425           0.905091         0.890538        0.024208   \n",
       "18           0.859898           0.912208         0.897772        0.027032   \n",
       "19           0.872188           0.909188         0.899216        0.019330   \n",
       "20           0.837135           0.926516         0.893454        0.040024   \n",
       "21           0.864761           0.913216         0.897610        0.023238   \n",
       "22           0.865694           0.913718         0.900410        0.024770   \n",
       "23           0.877385           0.903527         0.901529        0.018951   \n",
       "24           0.851071           0.917535         0.877676        0.028707   \n",
       "25           0.860644           0.910811         0.892155        0.022407   \n",
       "26           0.863744           0.919797         0.899008        0.025069   \n",
       "27           0.855035           0.904260         0.890402        0.025203   \n",
       "28           0.853591           0.902425         0.875452        0.020261   \n",
       "29           0.882886           0.896459         0.889051        0.005610   \n",
       "30           0.884527           0.893212         0.895997        0.010685   \n",
       "31           0.881904           0.881024         0.889545        0.011434   \n",
       "32           0.865227           0.906030         0.880901        0.017949   \n",
       "33           0.881408           0.896867         0.892211        0.007664   \n",
       "34           0.880774           0.888948         0.892236        0.010950   \n",
       "35           0.890009           0.886749         0.895354        0.009953   \n",
       "\n",
       "    rank_test_score  \n",
       "0                33  \n",
       "1                33  \n",
       "2                33  \n",
       "3                33  \n",
       "4                29  \n",
       "5                29  \n",
       "6                29  \n",
       "7                29  \n",
       "8                27  \n",
       "9                28  \n",
       "10               26  \n",
       "11               25  \n",
       "12               21  \n",
       "13               23  \n",
       "14               20  \n",
       "15               18  \n",
       "16               17  \n",
       "17               13  \n",
       "18                5  \n",
       "19                3  \n",
       "20                9  \n",
       "21                6  \n",
       "22                2  \n",
       "23                1  \n",
       "24               22  \n",
       "25               12  \n",
       "26                4  \n",
       "27               14  \n",
       "28               24  \n",
       "29               16  \n",
       "30                7  \n",
       "31               15  \n",
       "32               19  \n",
       "33               11  \n",
       "34               10  \n",
       "35                8  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(optimalmodel_dt.cv_results_) #Number of test score columns*number of rows are how many tests were carried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_leaf': 20}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9015292140538281"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_dt.best_score_ #Cross Validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=46, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_XGB = XGBClassifier(random_state=46)\n",
    "model_XGB.fit(X_train_v, y_train_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.9627757509052987\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb = model_XGB.predict_proba(X_train_v)[:,1]\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_train_v, y_train_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.8880094588955348\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_xgb = model_XGB.predict(X_val)\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_val, y_val_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LEARN HOW XGB CLASSIFIER WORKS. HOW DOES FEATURE IMPORTANCE WORK HERE\n",
    "\n",
    "#Using more estimators increasing the train speed therefore 100 seemed suitable. \n",
    "#Higher max depth overfits the model. \n",
    "#subsample is used as the regularization effect\n",
    "#High learning rates makes algorithm faster but does not yield accurate results thus keeping it to 0.1 is a good number\n",
    "import xgboost as xgb\n",
    "\n",
    "XGB = xgb.XGBClassifier(max_depth=7, n_estimators=100, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1, random_state=48)\n",
    "\n",
    "XGB.fit(X_train,y_train)\n",
    "\n",
    "#Identifying the important features\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(XGB, max_num_features=50, height=0.8, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart gives up a much better representation of the important features useful to us, more so than the correlation matrix. We can deduce that the total day minutes and total evening minutes were critically important variables.\n",
    "On the other hand, the total international charges and total night charges were of lesser importance. \n",
    "\n",
    "These are plotted against the F score in the x-axis because as it is a measure of the tests accuracy and shows a more realistic measure of a tests performance by using both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid_xgb = {'max_depth':[3,5,10], \n",
    "                 'learning_rate':[0.1,0.5,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=110, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bytree=1,\n",
       "                                     gamma=0, learning_rate=0.1,\n",
       "                                     max_delta_step=0, max_depth=3,\n",
       "                                     min_child_weight=1, missing=None,\n",
       "                                     n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=57, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=True,\n",
       "                                     subsample=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.5, 1],\n",
       "                         'max_depth': [3, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_xgb = GridSearchCV(xgb.XGBClassifier(random_state=57), paramgrid_xgb, cv=skf, scoring=\"roc_auc\")\n",
    "optimalmodel_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bestestimator = optimalmodel_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'max_depth': 3}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9186346774324367"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_xgb.best_score_ #Cross Validation Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the RF classifier\n",
    "model_RF = RandomForestClassifier(random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=56, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF.fit(X_train_v, y_train_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 1.0\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_RF.predict_proba(X_train_v)[:,1]\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_train_v, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.9269717624148004\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model_RF.predict_proba(X_val)[:,1]\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersgridrf = {'max_depth':[3,5,7],\n",
    "                   'min_samples_leaf':[1,3,5]\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=110, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=58,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 7], 'min_samples_leaf': [1, 3, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_RF = GridSearchCV(RandomForestClassifier(random_state=58), parametersgridrf, cv=skf, scoring=\"roc_auc\")\n",
    "optimalmodel_RF.fit(X_train_v, y_train_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.324152</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.911259</td>\n",
       "      <td>0.869914</td>\n",
       "      <td>0.893465</td>\n",
       "      <td>0.891546</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294347</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.912402</td>\n",
       "      <td>0.871430</td>\n",
       "      <td>0.895064</td>\n",
       "      <td>0.892965</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279943</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.911122</td>\n",
       "      <td>0.872299</td>\n",
       "      <td>0.894341</td>\n",
       "      <td>0.892587</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.331842</td>\n",
       "      <td>0.018105</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.886677</td>\n",
       "      <td>0.905792</td>\n",
       "      <td>0.907400</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.315459</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.934103</td>\n",
       "      <td>0.882532</td>\n",
       "      <td>0.902624</td>\n",
       "      <td>0.906420</td>\n",
       "      <td>0.021224</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.306593</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.929364</td>\n",
       "      <td>0.887714</td>\n",
       "      <td>0.903178</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.017190</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.353204</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.939376</td>\n",
       "      <td>0.884833</td>\n",
       "      <td>0.904254</td>\n",
       "      <td>0.909488</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.361047</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>0.022173</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.891143</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.911864</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.342194</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.933799</td>\n",
       "      <td>0.889177</td>\n",
       "      <td>0.901963</td>\n",
       "      <td>0.908313</td>\n",
       "      <td>0.018762</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.324152      0.088799         0.020620        0.006477   \n",
       "1       0.294347      0.017008         0.016931        0.001731   \n",
       "2       0.279943      0.015694         0.024645        0.012313   \n",
       "3       0.331842      0.018105         0.017067        0.000742   \n",
       "4       0.315459      0.003542         0.018263        0.001603   \n",
       "5       0.306593      0.003113         0.020949        0.000165   \n",
       "6       0.353204      0.009651         0.023590        0.007832   \n",
       "7       0.361047      0.008644         0.022173        0.003787   \n",
       "8       0.342194      0.000304         0.019989        0.003240   \n",
       "\n",
       "  param_max_depth param_min_samples_leaf  \\\n",
       "0               3                      1   \n",
       "1               3                      3   \n",
       "2               3                      5   \n",
       "3               5                      1   \n",
       "4               5                      3   \n",
       "5               5                      5   \n",
       "6               7                      1   \n",
       "7               7                      3   \n",
       "8               7                      5   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "0  {'max_depth': 3, 'min_samples_leaf': 1}           0.911259   \n",
       "1  {'max_depth': 3, 'min_samples_leaf': 3}           0.912402   \n",
       "2  {'max_depth': 3, 'min_samples_leaf': 5}           0.911122   \n",
       "3  {'max_depth': 5, 'min_samples_leaf': 1}           0.929730   \n",
       "4  {'max_depth': 5, 'min_samples_leaf': 3}           0.934103   \n",
       "5  {'max_depth': 5, 'min_samples_leaf': 5}           0.929364   \n",
       "6  {'max_depth': 7, 'min_samples_leaf': 1}           0.939376   \n",
       "7  {'max_depth': 7, 'min_samples_leaf': 3}           0.935719   \n",
       "8  {'max_depth': 7, 'min_samples_leaf': 5}           0.933799   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.869914           0.893465         0.891546        0.016934   \n",
       "1           0.871430           0.895064         0.892965        0.016792   \n",
       "2           0.872299           0.894341         0.892587        0.015898   \n",
       "3           0.886677           0.905792         0.907400        0.017613   \n",
       "4           0.882532           0.902624         0.906420        0.021224   \n",
       "5           0.887714           0.903178         0.906752        0.017190   \n",
       "6           0.884833           0.904254         0.909488        0.022573   \n",
       "7           0.891143           0.908730         0.911864        0.018333   \n",
       "8           0.889177           0.901963         0.908313        0.018762   \n",
       "\n",
       "   rank_test_score  \n",
       "0                9  \n",
       "1                7  \n",
       "2                8  \n",
       "3                4  \n",
       "4                6  \n",
       "5                5  \n",
       "6                2  \n",
       "7                1  \n",
       "8                3  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(optimalmodel_RF.cv_results_) #Number of test score columns*number of rows are how many tests were carried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118638968756314"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_RF.best_score_ #Cross Validation Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameter Tuning 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By adding additional parameters we are to trying to improve on our cross validation score\n",
    "\n",
    "parametersgridrf2 = {'max_depth':[3,5,7,9],\n",
    "                   'min_samples_leaf':[1,3,5,7],\n",
    "                   'n_estimators':[200],\n",
    "                    'min_samples_split':[5,7,9,11]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=110, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=58,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 7, 9],\n",
       "                         'min_samples_leaf': [1, 3, 5, 7],\n",
       "                         'min_samples_split': [5, 7, 9, 11],\n",
       "                         'n_estimators': [200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning new variables to the optimal models to avoid confusion with the previous\n",
    "\n",
    "optimalmodel_RF2 = GridSearchCV(RandomForestClassifier(random_state=58), parametersgridrf2, cv=skf, scoring=\"roc_auc\")\n",
    "optimalmodel_RF2.fit(X_train_v, y_train_v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594352</td>\n",
       "      <td>0.035886</td>\n",
       "      <td>0.035262</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.904584</td>\n",
       "      <td>0.868710</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560864</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.031422</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.903502</td>\n",
       "      <td>0.868740</td>\n",
       "      <td>0.891104</td>\n",
       "      <td>0.887782</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600689</td>\n",
       "      <td>0.055073</td>\n",
       "      <td>0.039772</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.903533</td>\n",
       "      <td>0.867734</td>\n",
       "      <td>0.891150</td>\n",
       "      <td>0.887472</td>\n",
       "      <td>0.014844</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.559883</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.032752</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.867872</td>\n",
       "      <td>0.891196</td>\n",
       "      <td>0.887508</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.536778</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.039310</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.904416</td>\n",
       "      <td>0.869822</td>\n",
       "      <td>0.891965</td>\n",
       "      <td>0.888735</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.609123</td>\n",
       "      <td>0.051292</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.904035</td>\n",
       "      <td>0.869838</td>\n",
       "      <td>0.892057</td>\n",
       "      <td>0.888643</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.564874</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.031194</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.904157</td>\n",
       "      <td>0.868999</td>\n",
       "      <td>0.891519</td>\n",
       "      <td>0.888225</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.537738</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.903990</td>\n",
       "      <td>0.869045</td>\n",
       "      <td>0.891596</td>\n",
       "      <td>0.888210</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.534989</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.037594</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.902786</td>\n",
       "      <td>0.872162</td>\n",
       "      <td>0.890996</td>\n",
       "      <td>0.888648</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.534701</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.902786</td>\n",
       "      <td>0.872162</td>\n",
       "      <td>0.890996</td>\n",
       "      <td>0.888648</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.538851</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.902786</td>\n",
       "      <td>0.872162</td>\n",
       "      <td>0.890996</td>\n",
       "      <td>0.888648</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.553691</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.036552</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.902801</td>\n",
       "      <td>0.872299</td>\n",
       "      <td>0.891058</td>\n",
       "      <td>0.888719</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.550957</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.871765</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.887985</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.556238</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.871765</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.887985</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.560885</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.036710</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.871765</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.887985</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.939782</td>\n",
       "      <td>0.062211</td>\n",
       "      <td>0.054010</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.871765</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.887985</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.832798</td>\n",
       "      <td>0.150571</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.931589</td>\n",
       "      <td>0.885093</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.905164</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.641394</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.931528</td>\n",
       "      <td>0.885809</td>\n",
       "      <td>0.896964</td>\n",
       "      <td>0.904767</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.631592</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.033769</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.932168</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.895656</td>\n",
       "      <td>0.904336</td>\n",
       "      <td>0.020139</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.647955</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.035190</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.930339</td>\n",
       "      <td>0.886251</td>\n",
       "      <td>0.896241</td>\n",
       "      <td>0.904277</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.637254</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>0.035049</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.930294</td>\n",
       "      <td>0.882426</td>\n",
       "      <td>0.899625</td>\n",
       "      <td>0.904115</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.646392</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>0.040645</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.930095</td>\n",
       "      <td>0.883127</td>\n",
       "      <td>0.897518</td>\n",
       "      <td>0.903580</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.624646</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.930354</td>\n",
       "      <td>0.883416</td>\n",
       "      <td>0.898394</td>\n",
       "      <td>0.904055</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.698735</td>\n",
       "      <td>0.088688</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.930217</td>\n",
       "      <td>0.883782</td>\n",
       "      <td>0.897118</td>\n",
       "      <td>0.903706</td>\n",
       "      <td>0.019521</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.650758</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>0.031648</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928282</td>\n",
       "      <td>0.891752</td>\n",
       "      <td>0.898594</td>\n",
       "      <td>0.906209</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.625463</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.034919</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928282</td>\n",
       "      <td>0.891752</td>\n",
       "      <td>0.898594</td>\n",
       "      <td>0.906209</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.727378</td>\n",
       "      <td>0.130014</td>\n",
       "      <td>0.037307</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928282</td>\n",
       "      <td>0.891752</td>\n",
       "      <td>0.898594</td>\n",
       "      <td>0.906209</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.628680</td>\n",
       "      <td>0.019289</td>\n",
       "      <td>0.036256</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.927672</td>\n",
       "      <td>0.890350</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.905595</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.609709</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.926270</td>\n",
       "      <td>0.887455</td>\n",
       "      <td>0.898271</td>\n",
       "      <td>0.903999</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.620734</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.038764</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.926270</td>\n",
       "      <td>0.887455</td>\n",
       "      <td>0.898271</td>\n",
       "      <td>0.903999</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.698948</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.039662</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.933799</td>\n",
       "      <td>0.894419</td>\n",
       "      <td>0.902855</td>\n",
       "      <td>0.910358</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.786781</td>\n",
       "      <td>0.057169</td>\n",
       "      <td>0.042493</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.933082</td>\n",
       "      <td>0.892651</td>\n",
       "      <td>0.899809</td>\n",
       "      <td>0.908514</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.797864</td>\n",
       "      <td>0.132096</td>\n",
       "      <td>0.052207</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.931711</td>\n",
       "      <td>0.894434</td>\n",
       "      <td>0.906900</td>\n",
       "      <td>0.911015</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.754619</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.933433</td>\n",
       "      <td>0.895715</td>\n",
       "      <td>0.905316</td>\n",
       "      <td>0.911488</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.696022</td>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.041367</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>0.893779</td>\n",
       "      <td>0.904008</td>\n",
       "      <td>0.910336</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.706973</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.935048</td>\n",
       "      <td>0.892560</td>\n",
       "      <td>0.899840</td>\n",
       "      <td>0.909149</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.705514</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.037211</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.930614</td>\n",
       "      <td>0.892819</td>\n",
       "      <td>0.899456</td>\n",
       "      <td>0.907629</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.753498</td>\n",
       "      <td>0.053582</td>\n",
       "      <td>0.045246</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.930614</td>\n",
       "      <td>0.892819</td>\n",
       "      <td>0.899456</td>\n",
       "      <td>0.907629</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.758605</td>\n",
       "      <td>0.051976</td>\n",
       "      <td>0.036620</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.930614</td>\n",
       "      <td>0.892819</td>\n",
       "      <td>0.899456</td>\n",
       "      <td>0.907629</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.853927</td>\n",
       "      <td>0.109899</td>\n",
       "      <td>0.051340</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.931985</td>\n",
       "      <td>0.890960</td>\n",
       "      <td>0.900348</td>\n",
       "      <td>0.907764</td>\n",
       "      <td>0.017550</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.555133</td>\n",
       "      <td>0.207161</td>\n",
       "      <td>0.092550</td>\n",
       "      <td>0.032742</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.931757</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.897241</td>\n",
       "      <td>0.908014</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.072824</td>\n",
       "      <td>0.509549</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.931757</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.897241</td>\n",
       "      <td>0.908014</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.641881</td>\n",
       "      <td>0.042430</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.931757</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.897241</td>\n",
       "      <td>0.908014</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.682330</td>\n",
       "      <td>0.111364</td>\n",
       "      <td>0.029797</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.931757</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.897241</td>\n",
       "      <td>0.908014</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.783462</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>0.032769</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.931254</td>\n",
       "      <td>0.904386</td>\n",
       "      <td>0.903362</td>\n",
       "      <td>0.913001</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.031730</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.931391</td>\n",
       "      <td>0.901689</td>\n",
       "      <td>0.904101</td>\n",
       "      <td>0.912393</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.615621</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.031055</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.932519</td>\n",
       "      <td>0.902908</td>\n",
       "      <td>0.902224</td>\n",
       "      <td>0.912550</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.649279</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.031353</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.931726</td>\n",
       "      <td>0.904828</td>\n",
       "      <td>0.903008</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.620191</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.932336</td>\n",
       "      <td>0.901978</td>\n",
       "      <td>0.900978</td>\n",
       "      <td>0.911764</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.614888</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.031411</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.932549</td>\n",
       "      <td>0.898488</td>\n",
       "      <td>0.895118</td>\n",
       "      <td>0.908718</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.621202</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.031725</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.933601</td>\n",
       "      <td>0.901308</td>\n",
       "      <td>0.899317</td>\n",
       "      <td>0.911408</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.677794</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.034909</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 3, 'min_s...</td>\n",
       "      <td>0.930964</td>\n",
       "      <td>0.899204</td>\n",
       "      <td>0.900978</td>\n",
       "      <td>0.910382</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.604570</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.031165</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928983</td>\n",
       "      <td>0.897741</td>\n",
       "      <td>0.900732</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.602013</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928983</td>\n",
       "      <td>0.897741</td>\n",
       "      <td>0.900732</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.597478</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.031781</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928983</td>\n",
       "      <td>0.897741</td>\n",
       "      <td>0.900732</td>\n",
       "      <td>0.909152</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.600563</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 5, 'min_s...</td>\n",
       "      <td>0.928175</td>\n",
       "      <td>0.895974</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.908591</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.592369</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.926514</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.907047</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.589303</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.926514</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.907047</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.593512</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.031035</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.926514</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.907047</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.590499</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 7, 'min_s...</td>\n",
       "      <td>0.926514</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>0.900117</td>\n",
       "      <td>0.907047</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.594352      0.035886         0.035262        0.004923   \n",
       "1        0.560864      0.024563         0.031422        0.002601   \n",
       "2        0.600689      0.055073         0.039772        0.003598   \n",
       "3        0.559883      0.006366         0.032752        0.003754   \n",
       "4        0.536778      0.006169         0.039310        0.004668   \n",
       "5        0.609123      0.051292         0.031142        0.000856   \n",
       "6        0.564874      0.020280         0.031194        0.002506   \n",
       "7        0.537738      0.011365         0.031242        0.002704   \n",
       "8        0.534989      0.006519         0.037594        0.004208   \n",
       "9        0.534701      0.006701         0.032325        0.003099   \n",
       "10       0.538851      0.011527         0.035652        0.002666   \n",
       "11       0.553691      0.020213         0.036552        0.003818   \n",
       "12       0.550957      0.009429         0.034028        0.003160   \n",
       "13       0.556238      0.010255         0.034955        0.004067   \n",
       "14       0.560885      0.008500         0.036710        0.007407   \n",
       "15       0.939782      0.062211         0.054010        0.029514   \n",
       "16       0.832798      0.150571         0.046963        0.008641   \n",
       "17       0.641394      0.002468         0.036687        0.004539   \n",
       "18       0.631592      0.001509         0.033769        0.005661   \n",
       "19       0.647955      0.023431         0.035190        0.004019   \n",
       "20       0.637254      0.011603         0.035049        0.003700   \n",
       "21       0.646392      0.022609         0.040645        0.008907   \n",
       "22       0.624646      0.013127         0.037841        0.004770   \n",
       "23       0.698735      0.088688         0.038888        0.002373   \n",
       "24       0.650758      0.054643         0.031648        0.001130   \n",
       "25       0.625463      0.014778         0.034919        0.004174   \n",
       "26       0.727378      0.130014         0.037307        0.005235   \n",
       "27       0.628680      0.019289         0.036256        0.003042   \n",
       "28       0.609709      0.005274         0.038252        0.004107   \n",
       "29       0.620734      0.010728         0.038764        0.004987   \n",
       "..            ...           ...              ...             ...   \n",
       "34       0.698948      0.009686         0.039662        0.001983   \n",
       "35       0.786781      0.057169         0.042493        0.008575   \n",
       "36       0.797864      0.132096         0.052207        0.009799   \n",
       "37       0.754619      0.101040         0.041394        0.001048   \n",
       "38       0.696022      0.014347         0.041367        0.003969   \n",
       "39       0.706973      0.009714         0.038595        0.003933   \n",
       "40       0.705514      0.011565         0.037211        0.004582   \n",
       "41       0.753498      0.053582         0.045246        0.015042   \n",
       "42       0.758605      0.051976         0.036620        0.003468   \n",
       "43       0.853927      0.109899         0.051340        0.008529   \n",
       "44       1.555133      0.207161         0.092550        0.032742   \n",
       "45       1.072824      0.509549         0.036214        0.001040   \n",
       "46       0.641881      0.042430         0.036207        0.004141   \n",
       "47       0.682330      0.111364         0.029797        0.000685   \n",
       "48       0.783462      0.157051         0.032769        0.001131   \n",
       "49       0.622545      0.005515         0.031730        0.000980   \n",
       "50       0.615621      0.003989         0.031055        0.000488   \n",
       "51       0.649279      0.050047         0.031353        0.001436   \n",
       "52       0.620191      0.004600         0.031631        0.000109   \n",
       "53       0.614888      0.006259         0.031411        0.000669   \n",
       "54       0.621202      0.010795         0.031725        0.000797   \n",
       "55       0.677794      0.012640         0.034909        0.001983   \n",
       "56       0.604570      0.003085         0.031165        0.000232   \n",
       "57       0.602013      0.003620         0.031331        0.000948   \n",
       "58       0.597478      0.003744         0.031781        0.000972   \n",
       "59       0.600563      0.004096         0.031674        0.001267   \n",
       "60       0.592369      0.006187         0.030769        0.000148   \n",
       "61       0.589303      0.000645         0.031250        0.000581   \n",
       "62       0.593512      0.009558         0.031035        0.000362   \n",
       "63       0.590499      0.002507         0.030777        0.000445   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0                3                      1                       5   \n",
       "1                3                      1                       7   \n",
       "2                3                      1                       9   \n",
       "3                3                      1                      11   \n",
       "4                3                      3                       5   \n",
       "5                3                      3                       7   \n",
       "6                3                      3                       9   \n",
       "7                3                      3                      11   \n",
       "8                3                      5                       5   \n",
       "9                3                      5                       7   \n",
       "10               3                      5                       9   \n",
       "11               3                      5                      11   \n",
       "12               3                      7                       5   \n",
       "13               3                      7                       7   \n",
       "14               3                      7                       9   \n",
       "15               3                      7                      11   \n",
       "16               5                      1                       5   \n",
       "17               5                      1                       7   \n",
       "18               5                      1                       9   \n",
       "19               5                      1                      11   \n",
       "20               5                      3                       5   \n",
       "21               5                      3                       7   \n",
       "22               5                      3                       9   \n",
       "23               5                      3                      11   \n",
       "24               5                      5                       5   \n",
       "25               5                      5                       7   \n",
       "26               5                      5                       9   \n",
       "27               5                      5                      11   \n",
       "28               5                      7                       5   \n",
       "29               5                      7                       7   \n",
       "..             ...                    ...                     ...   \n",
       "34               7                      1                       9   \n",
       "35               7                      1                      11   \n",
       "36               7                      3                       5   \n",
       "37               7                      3                       7   \n",
       "38               7                      3                       9   \n",
       "39               7                      3                      11   \n",
       "40               7                      5                       5   \n",
       "41               7                      5                       7   \n",
       "42               7                      5                       9   \n",
       "43               7                      5                      11   \n",
       "44               7                      7                       5   \n",
       "45               7                      7                       7   \n",
       "46               7                      7                       9   \n",
       "47               7                      7                      11   \n",
       "48               9                      1                       5   \n",
       "49               9                      1                       7   \n",
       "50               9                      1                       9   \n",
       "51               9                      1                      11   \n",
       "52               9                      3                       5   \n",
       "53               9                      3                       7   \n",
       "54               9                      3                       9   \n",
       "55               9                      3                      11   \n",
       "56               9                      5                       5   \n",
       "57               9                      5                       7   \n",
       "58               9                      5                       9   \n",
       "59               9                      5                      11   \n",
       "60               9                      7                       5   \n",
       "61               9                      7                       7   \n",
       "62               9                      7                       9   \n",
       "63               9                      7                      11   \n",
       "\n",
       "   param_n_estimators                                             params  \\\n",
       "0                 200  {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...   \n",
       "1                 200  {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...   \n",
       "2                 200  {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...   \n",
       "3                 200  {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...   \n",
       "4                 200  {'max_depth': 3, 'min_samples_leaf': 3, 'min_s...   \n",
       "5                 200  {'max_depth': 3, 'min_samples_leaf': 3, 'min_s...   \n",
       "6                 200  {'max_depth': 3, 'min_samples_leaf': 3, 'min_s...   \n",
       "7                 200  {'max_depth': 3, 'min_samples_leaf': 3, 'min_s...   \n",
       "8                 200  {'max_depth': 3, 'min_samples_leaf': 5, 'min_s...   \n",
       "9                 200  {'max_depth': 3, 'min_samples_leaf': 5, 'min_s...   \n",
       "10                200  {'max_depth': 3, 'min_samples_leaf': 5, 'min_s...   \n",
       "11                200  {'max_depth': 3, 'min_samples_leaf': 5, 'min_s...   \n",
       "12                200  {'max_depth': 3, 'min_samples_leaf': 7, 'min_s...   \n",
       "13                200  {'max_depth': 3, 'min_samples_leaf': 7, 'min_s...   \n",
       "14                200  {'max_depth': 3, 'min_samples_leaf': 7, 'min_s...   \n",
       "15                200  {'max_depth': 3, 'min_samples_leaf': 7, 'min_s...   \n",
       "16                200  {'max_depth': 5, 'min_samples_leaf': 1, 'min_s...   \n",
       "17                200  {'max_depth': 5, 'min_samples_leaf': 1, 'min_s...   \n",
       "18                200  {'max_depth': 5, 'min_samples_leaf': 1, 'min_s...   \n",
       "19                200  {'max_depth': 5, 'min_samples_leaf': 1, 'min_s...   \n",
       "20                200  {'max_depth': 5, 'min_samples_leaf': 3, 'min_s...   \n",
       "21                200  {'max_depth': 5, 'min_samples_leaf': 3, 'min_s...   \n",
       "22                200  {'max_depth': 5, 'min_samples_leaf': 3, 'min_s...   \n",
       "23                200  {'max_depth': 5, 'min_samples_leaf': 3, 'min_s...   \n",
       "24                200  {'max_depth': 5, 'min_samples_leaf': 5, 'min_s...   \n",
       "25                200  {'max_depth': 5, 'min_samples_leaf': 5, 'min_s...   \n",
       "26                200  {'max_depth': 5, 'min_samples_leaf': 5, 'min_s...   \n",
       "27                200  {'max_depth': 5, 'min_samples_leaf': 5, 'min_s...   \n",
       "28                200  {'max_depth': 5, 'min_samples_leaf': 7, 'min_s...   \n",
       "29                200  {'max_depth': 5, 'min_samples_leaf': 7, 'min_s...   \n",
       "..                ...                                                ...   \n",
       "34                200  {'max_depth': 7, 'min_samples_leaf': 1, 'min_s...   \n",
       "35                200  {'max_depth': 7, 'min_samples_leaf': 1, 'min_s...   \n",
       "36                200  {'max_depth': 7, 'min_samples_leaf': 3, 'min_s...   \n",
       "37                200  {'max_depth': 7, 'min_samples_leaf': 3, 'min_s...   \n",
       "38                200  {'max_depth': 7, 'min_samples_leaf': 3, 'min_s...   \n",
       "39                200  {'max_depth': 7, 'min_samples_leaf': 3, 'min_s...   \n",
       "40                200  {'max_depth': 7, 'min_samples_leaf': 5, 'min_s...   \n",
       "41                200  {'max_depth': 7, 'min_samples_leaf': 5, 'min_s...   \n",
       "42                200  {'max_depth': 7, 'min_samples_leaf': 5, 'min_s...   \n",
       "43                200  {'max_depth': 7, 'min_samples_leaf': 5, 'min_s...   \n",
       "44                200  {'max_depth': 7, 'min_samples_leaf': 7, 'min_s...   \n",
       "45                200  {'max_depth': 7, 'min_samples_leaf': 7, 'min_s...   \n",
       "46                200  {'max_depth': 7, 'min_samples_leaf': 7, 'min_s...   \n",
       "47                200  {'max_depth': 7, 'min_samples_leaf': 7, 'min_s...   \n",
       "48                200  {'max_depth': 9, 'min_samples_leaf': 1, 'min_s...   \n",
       "49                200  {'max_depth': 9, 'min_samples_leaf': 1, 'min_s...   \n",
       "50                200  {'max_depth': 9, 'min_samples_leaf': 1, 'min_s...   \n",
       "51                200  {'max_depth': 9, 'min_samples_leaf': 1, 'min_s...   \n",
       "52                200  {'max_depth': 9, 'min_samples_leaf': 3, 'min_s...   \n",
       "53                200  {'max_depth': 9, 'min_samples_leaf': 3, 'min_s...   \n",
       "54                200  {'max_depth': 9, 'min_samples_leaf': 3, 'min_s...   \n",
       "55                200  {'max_depth': 9, 'min_samples_leaf': 3, 'min_s...   \n",
       "56                200  {'max_depth': 9, 'min_samples_leaf': 5, 'min_s...   \n",
       "57                200  {'max_depth': 9, 'min_samples_leaf': 5, 'min_s...   \n",
       "58                200  {'max_depth': 9, 'min_samples_leaf': 5, 'min_s...   \n",
       "59                200  {'max_depth': 9, 'min_samples_leaf': 5, 'min_s...   \n",
       "60                200  {'max_depth': 9, 'min_samples_leaf': 7, 'min_s...   \n",
       "61                200  {'max_depth': 9, 'min_samples_leaf': 7, 'min_s...   \n",
       "62                200  {'max_depth': 9, 'min_samples_leaf': 7, 'min_s...   \n",
       "63                200  {'max_depth': 9, 'min_samples_leaf': 7, 'min_s...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.904584           0.868710           0.891134         0.888143   \n",
       "1            0.903502           0.868740           0.891104         0.887782   \n",
       "2            0.903533           0.867734           0.891150         0.887472   \n",
       "3            0.903456           0.867872           0.891196         0.887508   \n",
       "4            0.904416           0.869822           0.891965         0.888735   \n",
       "5            0.904035           0.869838           0.892057         0.888643   \n",
       "6            0.904157           0.868999           0.891519         0.888225   \n",
       "7            0.903990           0.869045           0.891596         0.888210   \n",
       "8            0.902786           0.872162           0.890996         0.888648   \n",
       "9            0.902786           0.872162           0.890996         0.888648   \n",
       "10           0.902786           0.872162           0.890996         0.888648   \n",
       "11           0.902801           0.872299           0.891058         0.888719   \n",
       "12           0.902131           0.871765           0.890058         0.887985   \n",
       "13           0.902131           0.871765           0.890058         0.887985   \n",
       "14           0.902131           0.871765           0.890058         0.887985   \n",
       "15           0.902131           0.871765           0.890058         0.887985   \n",
       "16           0.931589           0.885093           0.898810         0.905164   \n",
       "17           0.931528           0.885809           0.896964         0.904767   \n",
       "18           0.932168           0.885184           0.895656         0.904336   \n",
       "19           0.930339           0.886251           0.896241         0.904277   \n",
       "20           0.930294           0.882426           0.899625         0.904115   \n",
       "21           0.930095           0.883127           0.897518         0.903580   \n",
       "22           0.930354           0.883416           0.898394         0.904055   \n",
       "23           0.930217           0.883782           0.897118         0.903706   \n",
       "24           0.928282           0.891752           0.898594         0.906209   \n",
       "25           0.928282           0.891752           0.898594         0.906209   \n",
       "26           0.928282           0.891752           0.898594         0.906209   \n",
       "27           0.927672           0.890350           0.898763         0.905595   \n",
       "28           0.926270           0.887455           0.898271         0.903999   \n",
       "29           0.926270           0.887455           0.898271         0.903999   \n",
       "..                ...                ...                ...              ...   \n",
       "34           0.933799           0.894419           0.902855         0.910358   \n",
       "35           0.933082           0.892651           0.899809         0.908514   \n",
       "36           0.931711           0.894434           0.906900         0.911015   \n",
       "37           0.933433           0.895715           0.905316         0.911488   \n",
       "38           0.933220           0.893779           0.904008         0.910336   \n",
       "39           0.935048           0.892560           0.899840         0.909149   \n",
       "40           0.930614           0.892819           0.899456         0.907629   \n",
       "41           0.930614           0.892819           0.899456         0.907629   \n",
       "42           0.930614           0.892819           0.899456         0.907629   \n",
       "43           0.931985           0.890960           0.900348         0.907764   \n",
       "44           0.931757           0.895044           0.897241         0.908014   \n",
       "45           0.931757           0.895044           0.897241         0.908014   \n",
       "46           0.931757           0.895044           0.897241         0.908014   \n",
       "47           0.931757           0.895044           0.897241         0.908014   \n",
       "48           0.931254           0.904386           0.903362         0.913001   \n",
       "49           0.931391           0.901689           0.904101         0.912393   \n",
       "50           0.932519           0.902908           0.902224         0.912550   \n",
       "51           0.931726           0.904828           0.903008         0.913187   \n",
       "52           0.932336           0.901978           0.900978         0.911764   \n",
       "53           0.932549           0.898488           0.895118         0.908718   \n",
       "54           0.933601           0.901308           0.899317         0.911408   \n",
       "55           0.930964           0.899204           0.900978         0.910382   \n",
       "56           0.928983           0.897741           0.900732         0.909152   \n",
       "57           0.928983           0.897741           0.900732         0.909152   \n",
       "58           0.928983           0.897741           0.900732         0.909152   \n",
       "59           0.928175           0.895974           0.901624         0.908591   \n",
       "60           0.926514           0.894511           0.900117         0.907047   \n",
       "61           0.926514           0.894511           0.900117         0.907047   \n",
       "62           0.926514           0.894511           0.900117         0.907047   \n",
       "63           0.926514           0.894511           0.900117         0.907047   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.014798               57  \n",
       "1         0.014385               62  \n",
       "2         0.014844               64  \n",
       "3         0.014760               63  \n",
       "4         0.014307               49  \n",
       "5         0.014168               54  \n",
       "6         0.014541               55  \n",
       "7         0.014466               56  \n",
       "8         0.012612               51  \n",
       "9         0.012612               51  \n",
       "10        0.012612               51  \n",
       "11        0.012562               50  \n",
       "12        0.012483               58  \n",
       "13        0.012483               58  \n",
       "14        0.012483               58  \n",
       "15        0.012483               58  \n",
       "16        0.019507               37  \n",
       "17        0.019463               38  \n",
       "18        0.020139               39  \n",
       "19        0.018875               40  \n",
       "20        0.019798               41  \n",
       "21        0.019648               48  \n",
       "22        0.019576               42  \n",
       "23        0.019521               47  \n",
       "24        0.015856               33  \n",
       "25        0.015856               33  \n",
       "26        0.015856               33  \n",
       "27        0.015984               36  \n",
       "28        0.016356               43  \n",
       "29        0.016356               43  \n",
       "..             ...              ...  \n",
       "34        0.016929               12  \n",
       "35        0.017616               20  \n",
       "36        0.015494                9  \n",
       "37        0.016005                7  \n",
       "38        0.016712               13  \n",
       "39        0.018553               17  \n",
       "40        0.016477               26  \n",
       "41        0.016477               26  \n",
       "42        0.016477               26  \n",
       "43        0.017550               25  \n",
       "44        0.016813               21  \n",
       "45        0.016813               21  \n",
       "46        0.016813               21  \n",
       "47        0.016813               21  \n",
       "48        0.012914                2  \n",
       "49        0.013469                5  \n",
       "50        0.014123                4  \n",
       "51        0.013130                1  \n",
       "52        0.014552                6  \n",
       "53        0.016907               18  \n",
       "54        0.015713                8  \n",
       "55        0.014572               11  \n",
       "56        0.014075               14  \n",
       "57        0.014075               14  \n",
       "58        0.014075               14  \n",
       "59        0.014039               19  \n",
       "60        0.013954               29  \n",
       "61        0.013954               29  \n",
       "62        0.013954               29  \n",
       "63        0.013954               29  \n",
       "\n",
       "[64 rows x 15 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(optimalmodel_RF2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 11,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_RF2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9131874948495388"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalmodel_RF2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the validation scores, I have found out that the best model was Random Forest Classifier before the Hyperparameter tuning. This produced a result of 0.9269717624148004. However, after hyperparameter tuning twice and by adding additional parameters, this produced results of 0.9118638968756314 and 0.9131874948495388 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, \n",
    "\n",
    "the scores for Decision Trees on the Validaton Training Data set were: 0.73645847823063 \n",
    "and after the Hyperparameter Tuning: 0.9015292140538281\n",
    "\n",
    "the scores for XG Boost on the Validation Training Data set were: 0.8880094588955348\n",
    "and after the Hyperparameter Tuning: 0.9186346774324367"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the 3 learner models were utilised to improve the performance on the baseline model where logistic regression was used and produced a ROC score of 0.6576992627625539. This could be particularly overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Discrimination Comparison (ROC_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will produce ROC curves of the learner models, Decision Trees, XG Boost, and Random Forest Classifiers. What ROC curves tell us are a measure of the True Positive Rate against the False Positive Rate. \n",
    "\n",
    "With values closer to 1 being a perfect classifier and those towards the 0.5 mark, representing 50% precision. \n",
    "\n",
    "All of our models produced results above 0.5, but the Random Forest Classifier produced the best results, as it was the most close to the 1.0 score. \n",
    "\n",
    "We shall draw some curves to demonstrate this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import roc_curve and auc\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we will be calculating the ROC_AUC of our Test data using the Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC of model = 0.893779112794393\n"
     ]
    }
   ],
   "source": [
    "#This gives me the probabilities of it being 0 or 1\n",
    "\n",
    "y_test_pred_proba = model_RF.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"ROC_AUC of model =\", roc_auc_score(y_test, y_test_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[582   7]\n",
      " [ 27  51]]\n"
     ]
    }
   ],
   "source": [
    "#Import confusion matrix \n",
    "\n",
    "#This plots the binary values\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print('Confusion Matrix:\\n', cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) \n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "class_names = set(y) \n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "thresh = cnf_matrix.max() \n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cnf_matrix[i, j] > thresh else 'black')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
